---
title: "Untitled"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
library(janitor)
library(readr)
library(dplyr)
library(tidyverse)
setwd("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/1. asylum application Demographics")
getwd()
migr_asyappctzm_parsed <- read_csv("migr_asyappctzm_parsed.csv")

df <- read.csv("migr_asyappctzm_parsed.csv")
colnames(df)

# Group by 'TIME' (which appears to be your country column) and sum all numeric columns
df_aggregated <- df %>%
  group_by(TIME) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE), .groups = "drop")

# View to confirm
View(df_aggregated)

getwd()
# Save as CSV to your current working directory
write.csv(df_aggregated, "aggregated_asyappctzm.csv", row.names = FALSE)

```

# Filtering For EU Countries In Freedom House

```{r, freedomhouse}

FreedomHouse <- read_csv("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/4. Freedom house/FreedomHouse.csv")
View(FreedomHouse)



FreedomHouse_Filtered <- FreedomHouse %>% 
  filter(`Country/Territory` == "Ukraine")

#Verify 
test <- unique(FreedomHouse_Filtered$`Country/Territory`)
test



```

# Load All CSVs

```{r}
setwd("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/12. Working Data")
getwd()
FreedomHouse <- read_csv("FreedomHouse.csv")
AssylumApplicationDemographics <- read_csv("AssylumApplicationDemographics.csv")
Education15_64 <- read_csv("Education15_64.csv")
EmploymentActivity20_64 <- read_csv("EmploymentActivity20_64.csv")
GDPMainComponents <- read_csv("GDPMainComponents.csv")
HICP <- read_csv("HICP.csv")
TempProtectionBeneficiaries <- read_csv("TempProtectionBeneficiaries.csv")
TempProtectionGranted <- read_csv("TempProtectionGranted.csv")
Unemployment <- read_csv("Unemployment.csv")



```

# Split GDP Main Component

```{r}
# Load your dataset
df <- read.csv("GDPMainComponents.csv", check.names = FALSE)

# Check real column names to confirm
colnames(df)

# OPTIONAL: Clean column names by replacing multiple dots with spaces
colnames(df) <- gsub("\\.+", " ", colnames(df))

# Confirm target column exists
colnames(df)

# Get unique values from the 'National accounts indicator (ESA 2010)' column
unique_values <- unique(df$`National accounts indicator (ESA 2010)`)

# Loop to split and save
for (val in unique_values) {
  
  # Subset the data
  subset_df <- df[df$`National accounts indicator (ESA 2010)` == val, ]
  
  # Clean the value to make it filename safe
  safe_name <- gsub("[^[:alnum:]_]", "_", val)
  
  # Save to CSV in working directory
  write.csv(subset_df, paste0(safe_name, ".csv"), row.names = FALSE)
}

# Confirm files saved
list.files(pattern = ".csv$")


```

# Split Education15-64.csv

```{r}
df <- read.csv("Education15_64.csv", check.names = FALSE)

# Confirm column names
colnames(df)

# OPTIONAL: Clean column names to remove unwanted dots
colnames(df) <- gsub("\\.+", " ", colnames(df))

# Confirm the target column exists
colnames(df)

# Get unique values from the ISCED 2011 column
unique_values <- unique(df$`International Standard Classification of Education (ISCED 2011)`)

# Loop to split and save
for (val in unique_values) {
  
  # Subset the data
  subset_df <- df[df$`International Standard Classification of Education (ISCED 2011)` == val, ]
  
  # Clean the value to make it filename safe
  safe_name <- gsub("[^[:alnum:]_]", "_", val)
  
  # Save to CSV in working directory
  write.csv(subset_df, paste0(safe_name, ".csv"), row.names = FALSE)
}

# Confirm files saved
list.files(pattern = ".csv$")

```

# Mass Import all CSVs

```{r}
# Set your working directory

# List all .csv files in the directory
file_list <- list.files(pattern = "\\.csv$", full.names = TRUE)

# Mass read into a named list
data_list <- lapply(file_list, read.csv)

# Name each list element after the file name (without .csv extension)
names(data_list) <- gsub("\\.csv$", "", basename(file_list))

# Check loaded dataset names
names(data_list)

list2env(data_list, envir = .GlobalEnv)


```

Global Truncation (failed - unsure why so I will start creating the master dataset and subset the final product)

```{r}
# Your expanded country list
# Expanded country list
eu_expanded <- c(
  "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic", "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
  "Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
  "Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
  "Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)

# Global filtering function
data_list <- lapply(data_list, function(df) {
  
  # Normalize column names to lowercase for consistent matching
  colnames(df) <- tolower(colnames(df))
  
  # Find a country column (case-insensitive)
  country_col <- grep("country|time|country/territory", colnames(df), value = TRUE)[1]
  
  if (!is.na(country_col)) {
    
    # Apply filter if country column exists
    df <- df[df[[country_col]] %in% eu_expanded, ]
  }
  
  return(df)
})


```

# Eliminate Austria from Assylum Application Demo

```{r}
AssylumApplicationDemographics <- AssylumApplicationDemographics[AssylumApplicationDemographics$TIME != "Austria", ]

```

# HICP Cleaning

```{r}
# Vector of countries to keep
eu_expanded <- c(
  "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic", "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
  "Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
  "Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
  "Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)
colnames(HICP)
# Filter HICP to keep only rows where TIME is in eu_expanded
HICP <- HICP[HICP$TIME %in% eu_expanded, ]

# Confirm
unique(HICP$TIME)






```

# Combine monthly refugee numbers and applicaiton acceptances.

```{r}
library(dplyr)
library(readr)

# Read in the files
beneficiaries <- read_csv("TempProtectionBeneficiaries.csv")
granted <- read_csv("TempProtectionGranted.csv")

# Define columns to drop
cols_to_drop <- c("Time frequency", "Unit of measure", 
                  "Country of citizenship", "Sex", "Age class")

# For beneficiaries dataset
beneficiaries_clean <- beneficiaries %>%
  select(-c("Time frequency", "Unit of measure", 
            "Country of citizenship", "Sex", "Age class")) %>%
  mutate(Class = "TempProtectionBeneficiaries")

# For granted dataset (only drop TIME)
granted_clean <- granted %>%
  select(-TIME) %>%
  mutate(Class = "TempProtectionGranted")

# Combine the cleaned datasets
Aggregated_Data <- bind_rows(beneficiaries_clean, granted_clean)

# Save to CSV
write_csv(Aggregated_Data, "Aggregated_Data.csv")

#extermly important, make sure you open the saved csv and verify that the time column was properly transmutated. if not you will have to manually fix it savfe the csv and reload which is why this next block of code rereads the data into the r enviornment

Aggregated_Data <- read_csv("Aggregated_Data.csv")

# aggregated data final cleaning 

# Assuming your dataset is called df (replace with actual name if different)


# Step 2: Filter dataset to only those countries
Aggregated_Data <- Aggregated_Data[Aggregated_Data$TIME %in% eu_expanded, ]

# Step 3: Rename 'time' column to 'Country'
colnames(Aggregated_Data)[colnames(Aggregated_Data) == "TIME"] <- "Country"

# Step 4: View the result
head(Aggregated_Data)


#for some reason when the second dataset is loaded into the aggregated dataset the countries all come back as NA so i manually copy pasted the countries and verified that they corresponded to the correct values

```

# start combining annual data

```{r}
library(dplyr)
library(readr)

# Read the files
employment <- read_csv("EmploymentActivity20_64.csv")
gdp <- read_csv("GDPMainComponents.csv")
education <- read_csv("Education15_64.csv")

# Columns to convert (for consistency)
cols_to_char <- c("2020", "2021", "2022", "2023", "2024")

# Clean, convert, and add Dataset column
employment_clean <- employment %>%
  mutate(across(all_of(cols_to_char), as.character)) %>%
  mutate(Dataset = "EmploymentActivity20_64")

gdp_clean <- gdp %>%
  mutate(across(all_of(cols_to_char), as.character)) %>%
  mutate(Dataset = "GDPMainComponents")

education_clean <- education %>%
  mutate(across(all_of(cols_to_char), as.character)) %>%
  mutate(Dataset = "Education15_64")

# Combine them
Aggregated_Data_2 <- bind_rows(employment_clean, gdp_clean, education_clean)

# Save to CSV
write_csv(Aggregated_Data_2, "Aggregated_Data_2.csv")

print("Aggregated_Data_2.csv created successfully.")


```

# start combining monthly data (unemployment HICP)

```{r}
library(dplyr)
library(readr)

# Read the files
hicp <- read_csv("HICP.csv")
unemployment <- read_csv("Unemployment.csv")

# Identify date columns
date_cols <- grep("^202", names(hicp), value = TRUE)

# Process HICP
hicp_clean <- hicp %>%
  mutate(across(all_of(date_cols), as.character))

# Process Unemployment
unemployment_clean <- unemployment %>%
  mutate(across(all_of(date_cols), as.character))

# Combine
Aggregated_Data_3 <- bind_rows(hicp_clean, unemployment_clean)

# Save to CSV
write_csv(Aggregated_Data_3, "Aggregated_Data_3.csv")
print("Aggregated_Data_3.csv created successfully.")
colnames((Aggregated_Data_3))


```

# Aggregaded_2 distill countries

```{r}
# Your list of countries
eu_expanded <- c(
  "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
  "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
  "Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
  "Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
  "Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)
Aggregated_Data_2[Aggregated_Data_2 == ":"] <- NA

# Assuming your dataset is called df
# Filter and rename
Aggregated_Data_2 <- Aggregated_Data_2[Aggregated_Data_2$TIME %in% eu_expanded, ]
names(Aggregated_Data_2)[names(Aggregated_Data_2) == "TIME"] <- "Country"


unique(Aggregated_Data_2$Country)
write.csv(Aggregated_Data_2, "Aggregated_Data_2", row.names = FALSE, fileEncoding = "UTF-8")
```

# Aggregaded_3 distill countries

```{r}
eu_expanded <- c(
  "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
  "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
  "Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
  "Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
  "Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)

# Assuming your dataset is called df
# Filter and rename
Aggregated_Data_3 <- Aggregated_Data_3[Aggregated_Data_3$TIME %in% eu_expanded, ]
names(Aggregated_Data_3)[names(Aggregated_Data_3) == "TIME"] <- "Country"

unique(Aggregated_Data_3$Country)
write.csv(Aggregated_Data_3, "Aggregated_Data_3", row.names = FALSE, fileEncoding = "UTF-8")

```

# Filtering Freedom House

```{r}
# Load your Freedom House data
freedom_house <- read.csv("FreedomHouse.csv")
colnames(freedom_house)
# Subset to relevant columns
FreedomHouseFiltered <- freedom_house[, c(
  "Country.Territory", "Edition", "A1", "A2", "B1", "B3", 
  "C2", "D1", "E1", "F1", "F3", "G1", "Total"
)]

# Filter for Ukraine only
FreedomHouseFiltered <- subset(FreedomHouseFiltered, `Country.Territory` == "Ukraine")


FreedomHouseFiltered <- FreedomHouseFiltered[FreedomHouseFiltered$Edition >= 2020 & FreedomHouseFiltered$Edition <= 2025, ]

# Rename 'Edition' to 'time'
colnames(FreedomHouseFiltered)[colnames(FreedomHouseFiltered) == "Edition"] <- "time"

colnames(FreedomHouse_Filtered)[colnames(FreedomHouse_Filtered) == "Country/Territory"] <- "Country"


# View to confirm
head(FreedomHouseFiltered)

# Save to CSV
write.csv(FreedomHouseFiltered, "FreedomHouseFiltered.csv", row.names = FALSE)


```

EU_Capitols df creation

```{r}
# Required for distance calculation
#install.packages("geosphere")
library(geosphere)

# Step 1: Create dataframe of countries, capitals, latitudes, longitudes
eu_capitals <- data.frame(
  Country = c("Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
              "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
              "Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
              "Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
              "Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"),
  
  Capital = c("Brussels", "Sofia", "Zagreb", "Nicosia", "Prague", "Prague",
              "Copenhagen", "Tallinn", "Helsinki", "Paris", "Berlin", "Athens",
              "Budapest", "Dublin", "Rome", "Riga", "Vilnius", "Luxembourg",
              "Valletta", "Amsterdam", "Warsaw", "Lisbon", "Bucharest", "Bratislava",
              "Ljubljana", "Madrid", "Stockholm", "Reykjavik", "Oslo", "Bern"),
  
  Latitude = c(50.8503, 42.6977, 45.8150, 35.1856, 50.0755, 50.0755,
               55.6761, 59.4370, 60.1695, 48.8566, 52.5200, 37.9838,
               47.4979, 53.3498, 41.9028, 56.9496, 54.6872, 49.6117,
               35.8997, 52.3676, 52.2297, 38.7169, 44.4268, 48.1486,
               46.0569, 40.4168, 59.3293, 64.1466, 59.9139, 46.9481),
  
  Longitude = c(4.3517, 23.3219, 15.9819, 33.3823, 14.4378, 14.4378,
                12.5683, 24.7535, 24.9354, 2.3522, 13.4050, 23.7275,
                19.0402, -6.2603, 12.4964, 24.1052, 25.2797, 6.1319,
                14.5146, 4.9041, 21.0122, -9.1399, 26.1025, 17.1077,
                14.5058, -3.7038, 18.0686, -21.9426, 10.7522, 7.4474)
)

# eliminate czechia
eu_capitals <- eu_capitals[eu_capitals$Country != "Czech Republic", ]


# Step 2: Define Kyiv coordinates
kyiv_coords <- c(30.5234, 50.4501)  # longitude, latitude

# Step 3: Calculate distance from Kyiv to each capital
eu_capitals$Distance_km <- distHaversine(
  matrix(c(eu_capitals$Longitude, eu_capitals$Latitude), ncol = 2),
  kyiv_coords
) / 1000  # Convert meters to kilometers

# Step 4: View the resulting dataset
print(eu_capitals)


#Bordering or not bordering?
# Define countries that border Ukraine
borders_ukraine <- c("Poland", "Slovakia", "Hungary", "Romania")

# Add binary column
eu_capitals$Borders_Ukraine <- ifelse(eu_capitals$Country %in% borders_ukraine, "Yes", "No")

# View result
print(eu_capitals)

write.csv(eu_capitals, "Kyiv_to_EU_Capitals_Distance.csv", row.names = FALSE)




#Map the countries:
# Load necessary packages
# Load required packages
library(ggplot2)
library(maps)

# Get world map data
world_map <- map_data("world")

# Subset to Europe region based on lat/long boundaries
europe_map <- subset(world_map, long > -25 & long < 45 & lat > 35 & lat < 70)

# Plot Europe map with capitals and Kyiv
ggplot() +
  geom_polygon(data = europe_map, aes(x = long, y = lat, group = group),
               fill = "lightgray", color = "white") +
  geom_point(data = eu_capitals, aes(x = Longitude, y = Latitude),
             color = "blue", size = 2) +
  geom_text(data = eu_capitals, aes(x = Longitude, y = Latitude, label = Capital),
            hjust = -0.1, vjust = -0.5, size = 3) +
  # Add Kyiv
  geom_point(aes(x = 30.5234, y = 50.4501), color = "red", size = 3) +
  geom_text(aes(x = 30.5234, y = 50.4501, label = "Kyiv"), hjust = -0.1, vjust = -0.5, size = 3) +
  coord_fixed(1.3) +
  theme_minimal() +
  ggtitle("Kyiv and EU+ Capitals - Europe Focused")



```

# Final cleaning of Aggregated_Data_2

```{r}
Aggregated_Data_2[Aggregated_Data_2 == ":"] <- NA

```

# Locally load all the final CVS to file to verify that they're cleaned

```{r}
write_csv(Aggregated_Data, "Aggregated_Data.csv")
write_csv(Aggregated_Data_2, "Aggregated_Data_2.csv")
write_csv(Aggregated_Data_3, "Aggregated_Data_3.csv")
write_csv(FreedomHouse_Filtered, "FreedomHouse_Filtered.csv")
write_csv(eu_capitals, "eu_capitals.csv")

```

# Take A moment to sweep enviornment to avoid crashed then reread the data into the dataset

```{r}
Aggregated_Data <- read.csv("Aggregated_Data.csv")
Aggregated_Data_2 <- read.csv("Aggregated_Data_2.csv")
Aggregated_Data_3 <- read.csv("Aggregated_Data_3.csv")
FreedomHouse_Filtered <- read.csv("FreedomHouse_Filtered.csv")
eu_capitals <- read.csv("eu_capitals.csv")

```
