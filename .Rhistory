library(janitor)
library(readr)
library(dplyr)
library(tidyverse)
setwd("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/1. asylum application Demographics")
getwd()
migr_asyappctzm_parsed <- read_csv("migr_asyappctzm_parsed.csv")
df <- read.csv("migr_asyappctzm_parsed.csv")
colnames(df)
# group the data by time and note that time is the country column for the time being then sum the numeric columns
df_aggregated <- df %>%
group_by(TIME) %>%
summarise(across(where(is.numeric), sum, na.rm = TRUE), .groups = "drop")
write.csv(df_aggregated, "aggregated_asyappctzm.csv", row.names = FALSE)
FreedomHouse <- read_csv("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/4. Freedom house/FreedomHouse.csv")
View(FreedomHouse)
FreedomHouse_Filtered <- FreedomHouse %>%
filter(`Country/Territory` == "Ukraine")
setwd("C:/Users/macle/OneDrive/Desktop/Capstone/DATA/12. Working Data")
getwd()
FreedomHouse <- read_csv("FreedomHouse.csv")
AssylumApplicationDemographics <- read_csv("AssylumApplicationDemographics.csv")
Education15_64 <- read_csv("Education15_64.csv")
EmploymentActivity20_64 <- read_csv("EmploymentActivity20_64.csv")
GDPMainComponents <- read_csv("GDPMainComponents.csv")
HICP <- read_csv("HICP.csv")
TempProtectionBeneficiaries <- read_csv("TempProtectionBeneficiaries.csv")
TempProtectionGranted <- read_csv("TempProtectionGranted.csv")
Unemployment <- read_csv("Unemployment.csv")
# set working df
df <- read.csv("GDPMainComponents.csv", check.names = FALSE)
#colname confirmation and cleaning
colnames(df)
colnames(df) <- gsub("\\.+", " ", colnames(df))
#  unique values from the ational accounts indicator (ESA 2010 column
unique_values <- unique(df$`National accounts indicator (ESA 2010)`)
# loop to split and save
for (val in unique_values) {
subset_df <- df[df$`National accounts indicator (ESA 2010)` == val, ]
safe_name <- gsub("[^[:alnum:]_]", "_", val)
write.csv(subset_df, paste0(safe_name, ".csv"), row.names = FALSE)
}
df <- read.csv("Education15_64.csv", check.names = FALSE)
# clean dots from colnames
colnames(df) <- gsub("\\.+", " ", colnames(df))
# acquire unique values from the ISCED 2011 column
unique_values <- unique(df$`International Standard Classification of Education (ISCED 2011)`)
# Loop to split and save
for (val in unique_values) {
subset_df <- df[df$`International Standard Classification of Education (ISCED 2011)` == val, ]
safe_name <- gsub("[^[:alnum:]_]", "_", val)
write.csv(subset_df, paste0(safe_name, ".csv"), row.names = FALSE)
}
# List all .csv files in the directory
file_list <- list.files(pattern = "\\.csv$", full.names = TRUE)
# mass read into named list
data_list <- lapply(file_list, read.csv)
# name elements after file name for tracking data sources in combined csv
names(data_list) <- gsub("\\.csv$", "", basename(file_list))
list2env(data_list, envir = .GlobalEnv)
# set the coutnries which will be used in analysis
eu_expanded <- c(
"Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic", "Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
"Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
"Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
"Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)
# filter globally
data_list <- lapply(data_list, function(df) {
colnames(df) <- tolower(colnames(df))
country_col <- grep("country|time|country/territory", colnames(df), value = TRUE)[1]
if (!is.na(country_col)) {
df <- df[df[[country_col]] %in% eu_expanded, ]
}
return(df)
})
AssylumApplicationDemographics <- AssylumApplicationDemographics[AssylumApplicationDemographics$TIME != "Austria", ]
HICP <- HICP[HICP$TIME %in% eu_expanded, ]
library(dplyr)
library(readr)
# read in the files
beneficiaries <- read_csv("TempProtectionBeneficiaries.csv")
granted <- read_csv("TempProtectionGranted.csv")
#define columns to drop
cols_to_drop <- c("Time frequency", "Unit of measure",
"Country of citizenship", "Sex", "Age class")
#  beneficiaries dataset
beneficiaries_clean <- beneficiaries %>%
select(-c("Time frequency", "Unit of measure",
"Country of citizenship", "Sex", "Age class")) %>%
mutate(Class = "TempProtectionBeneficiaries")
#  granted dataset (only drop TIME)
granted_clean <- granted %>%
select(-TIME) %>%
mutate(Class = "TempProtectionGranted")
# combine the cleaned datasets
Aggregated_Data <- bind_rows(beneficiaries_clean, granted_clean)
write_csv(Aggregated_Data, "Aggregated_Data.csv")
#extremely important, make sure you open the saved csv and verify that the time column was properly transmuted. if not you will have to manually fix it save the csv and reload which is why this next block of code rereads the data into the r environment
Aggregated_Data <- read_csv("Aggregated_Data.csv")
# aggregated data final cleaning
# Assuming your dataset is called df (replace with actual name if different)
# apply eu country filter
Aggregated_Data <- Aggregated_Data[Aggregated_Data$TIME %in% eu_expanded, ]
# rename time column to country
colnames(Aggregated_Data)[colnames(Aggregated_Data) == "TIME"] <- "Country"
#for some reason when the second data set is loaded into the aggregated dataset the countries all come back as NA so I manually copy pasted the countries and verified that they corresponded to the correct value.
library(dplyr)
library(readr)
employment <- read_csv("EmploymentActivity20_64.csv")
gdp <- read_csv("GDPMainComponents.csv")
education <- read_csv("Education15_64.csv")
# get correct dates to clean and convert
cols_to_char <- c("2020", "2021", "2022", "2023", "2024")
employment_clean <- employment %>%
mutate(across(all_of(cols_to_char), as.character)) %>%
mutate(Dataset = "EmploymentActivity20_64")
gdp_clean <- gdp %>%
mutate(across(all_of(cols_to_char), as.character)) %>%
mutate(Dataset = "GDPMainComponents")
education_clean <- education %>%
mutate(across(all_of(cols_to_char), as.character)) %>%
mutate(Dataset = "Education15_64")
# Combine them
Aggregated_Data_2 <- bind_rows(employment_clean, gdp_clean, education_clean)
write_csv(Aggregated_Data_2, "Aggregated_Data_2.csv")
library(dplyr)
library(readr)
hicp <- read_csv("HICP.csv")
unemployment <- read_csv("Unemployment.csv")
# Identify date columns
date_cols <- grep("^202", names(hicp), value = TRUE)
# process HICP
hicp_clean <- hicp %>%
mutate(across(all_of(date_cols), as.character))
# process Unemployment
unemployment_clean <- unemployment %>%
mutate(across(all_of(date_cols), as.character))
# combine
Aggregated_Data_3 <- bind_rows(hicp_clean, unemployment_clean)
write_csv(Aggregated_Data_3, "Aggregated_Data_3.csv")
print("Aggregated_Data_3.csv created successfully.")
colnames((Aggregated_Data_3))
# restate vector
eu_expanded <- c(
"Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
"Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
"Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
"Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
"Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)
Afregated_Data_2[Aggregated_Data_2 == ":"] <- NA
# Filter and rename
Aggregated_Data_2 <- Aggregated_Data_2[Aggregated_Data_2$TIME %in% eu_expanded, ]
names(Aggregated_Data_2)[names(Aggregated_Data_2) == "TIME"] <- "Country"
unique(Aggregated_Data_2$Country)
write.csv(Aggregated_Data_2, "Aggregated_Data_2", row.names = FALSE, fileEncoding = "UTF-8")
Aggregated_Data_2[Aggregated_Data_2 == ":"] <- NA
eu_expanded <- c(
"Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
"Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
"Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
"Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
"Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"
)
# Filter and rename
Aggregated_Data_3 <- Aggregated_Data_3[Aggregated_Data_3$TIME %in% eu_expanded, ]
names(Aggregated_Data_3)[names(Aggregated_Data_3) == "TIME"] <- "Country"
unique(Aggregated_Data_3$Country)
write.csv(Aggregated_Data_3, "Aggregated_Data_3", row.names = FALSE, fileEncoding = "UTF-8")
freedom_house <- read.csv("FreedomHouse.csv")
colnames(freedom_house)
# Subset to relevant columns
FreedomHouseFiltered <- freedom_house[, c(
"Country.Territory", "Edition", "A1", "A2", "B1", "B3",
"C2", "D1", "E1", "F1", "F3", "G1", "Total"
)]
# filter for Ukraine only
FreedomHouseFiltered <- subset(FreedomHouseFiltered, `Country.Territory` == "Ukraine")
FreedomHouseFiltered <- FreedomHouseFiltered[FreedomHouseFiltered$Edition >= 2020 & FreedomHouseFiltered$Edition <= 2025, ]
# Rename edition to time
colnames(FreedomHouseFiltered)[colnames(FreedomHouseFiltered) == "Edition"] <- "time"
colnames(FreedomHouse_Filtered)[colnames(FreedomHouse_Filtered) == "Country/Territory"] <- "Country"
write.csv(FreedomHouseFiltered, "FreedomHouseFiltered.csv", row.names = FALSE)
#install.packages("geosphere")
library(geosphere)
eu_capitals <- data.frame(
Country = c("Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Czech Republic",
"Denmark", "Estonia", "Finland", "France", "Germany", "Greece",
"Hungary", "Ireland", "Italy", "Latvia", "Lithuania", "Luxembourg",
"Malta", "Netherlands", "Poland", "Portugal", "Romania", "Slovakia",
"Slovenia", "Spain", "Sweden", "Iceland", "Norway", "Switzerland"),
Capital = c("Brussels", "Sofia", "Zagreb", "Nicosia", "Prague", "Prague",
"Copenhagen", "Tallinn", "Helsinki", "Paris", "Berlin", "Athens",
"Budapest", "Dublin", "Rome", "Riga", "Vilnius", "Luxembourg",
"Valletta", "Amsterdam", "Warsaw", "Lisbon", "Bucharest", "Bratislava",
"Ljubljana", "Madrid", "Stockholm", "Reykjavik", "Oslo", "Bern"),
Latitude = c(50.8503, 42.6977, 45.8150, 35.1856, 50.0755, 50.0755,
55.6761, 59.4370, 60.1695, 48.8566, 52.5200, 37.9838,
47.4979, 53.3498, 41.9028, 56.9496, 54.6872, 49.6117,
35.8997, 52.3676, 52.2297, 38.7169, 44.4268, 48.1486,
46.0569, 40.4168, 59.3293, 64.1466, 59.9139, 46.9481),
Longitude = c(4.3517, 23.3219, 15.9819, 33.3823, 14.4378, 14.4378,
12.5683, 24.7535, 24.9354, 2.3522, 13.4050, 23.7275,
19.0402, -6.2603, 12.4964, 24.1052, 25.2797, 6.1319,
14.5146, 4.9041, 21.0122, -9.1399, 26.1025, 17.1077,
14.5058, -3.7038, 18.0686, -21.9426, 10.7522, 7.4474)
)
eu_capitals <- eu_capitals[eu_capitals$Country != "Czech Republic", ]
kyiv_coords <- c(30.5234, 50.4501)  # longitude, latitude
eu_capitals$Distance_km <- distHaversine(
matrix(c(eu_capitals$Longitude, eu_capitals$Latitude), ncol = 2),
kyiv_coords
) / 1000  # Convert meters to kilometers
#Bordering or not bordering?
borders_ukraine <- c("Poland", "Slovakia", "Hungary", "Romania")
eu_capitals$Borders_Ukraine <- ifelse(eu_capitals$Country %in% borders_ukraine, "Yes", "No")
write.csv(eu_capitals, "Kyiv_to_EU_Capitals_Distance.csv", row.names = FALSE)
#map
library(ggplot2)
library(maps)
world_map <- map_data("world")
europe_map <- subset(world_map, long > -25 & long < 45 & lat > 35 & lat < 70)
ggplot() +
geom_polygon(data = europe_map, aes(x = long, y = lat, group = group),
fill = "lightgray", color = "white") +
geom_point(data = eu_capitals, aes(x = Longitude, y = Latitude),
color = "blue", size = 2) +
geom_text(data = eu_capitals, aes(x = Longitude, y = Latitude, label = Capital),
hjust = -0.1, vjust = -0.5, size = 3) +
# Add Kyiv
geom_point(aes(x = 30.5234, y = 50.4501), color = "red", size = 3) +
geom_text(aes(x = 30.5234, y = 50.4501, label = "Kyiv"), hjust = -0.1, vjust = -0.5, size = 3) +
coord_fixed(1.3) +
theme_minimal() +
ggtitle("Kyiv and EU+ Capitals - Europe Focused")
write_csv(Aggregated_Data, "Aggregated_Data.csv")
write_csv(Aggregated_Data_2, "Aggregated_Data_2.csv")
write_csv(Aggregated_Data_3, "Aggregated_Data_3.csv")
write_csv(FreedomHouse_Filtered, "FreedomHouse_Filtered.csv")
write_csv(eu_capitals, "eu_capitals.csv")
Aggregated_Data <- read.csv("Aggregated_Data.csv")
Aggregated_Data_2 <- read.csv("Aggregated_Data_2.csv")
Aggregated_Data_3 <- read.csv("Aggregated_Data_3.csv")
FreedomHouse_Filtered <- read.csv("FreedomHouse_Filtered.csv")
eu_capitals <- read.csv("eu_capitals.csv")
